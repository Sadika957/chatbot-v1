{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e42efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"google_api_key\"] = \"AIzaSyBMSTBqYv74VqltxMj7G8eUtbuQg8tUROg\"\n",
    "os.environ[\"google_cse_id\"] = \"94a6404e7eb494900\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf90e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# ðŸŒŸ FINAL HYBRID CHATBOT: Full Pipeline + Clickable Citations\n",
    "# =====================================================\n",
    "\n",
    "import os, re, json, requests\n",
    "from urllib.parse import quote\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, GoogleSearchAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun, GoogleSearchRun\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ”‘ API KEYS\n",
    "# -----------------------------\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ¤– LLM\n",
    "# -----------------------------\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0, api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ§  Vector DBs\n",
    "# -----------------------------\n",
    "PERSIST_DIR_1 = r\"C:\\Users\\sadika957\\Desktop\\chatbot\\scripts\\chroma_db_nomic\"\n",
    "PERSIST_DIR_2 = r\"C:\\Users\\sadika957\\Desktop\\chatbot\\scripts\\chroma_db_jsonl\"\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "db1 = Chroma(persist_directory=PERSIST_DIR_1, embedding_function=embeddings)\n",
    "db2 = Chroma(persist_directory=PERSIST_DIR_2, embedding_function=embeddings)\n",
    "retriever1 = db1.as_retriever(search_kwargs={\"k\": 8})\n",
    "retriever2 = db2.as_retriever(search_kwargs={\"k\": 8})\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸŒ External Tools\n",
    "# -----------------------------\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "google_tool = GoogleSearchRun(api_wrapper=GoogleSearchAPIWrapper(\n",
    "    google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID\n",
    "))\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ—‚ï¸ Memory\n",
    "# -----------------------------\n",
    "MEMORY_FILE = \"chat_memory.json\"\n",
    "\n",
    "def load_memory() -> List[Dict[str, str]]:\n",
    "    if os.path.exists(MEMORY_FILE):\n",
    "        try:\n",
    "            return json.load(open(MEMORY_FILE, \"r\", encoding=\"utf-8\"))\n",
    "        except:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def save_memory(mem: List[Dict[str, str]]):\n",
    "    json.dump(mem[-15:], open(MEMORY_FILE, \"w\", encoding=\"utf-8\"), indent=2)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ§© Utility Functions\n",
    "# -----------------------------\n",
    "def clean_query(q: str) -> str:\n",
    "    return re.sub(r\"[\\n\\r]+\", \" \", q.strip())\n",
    "\n",
    "def extractive_answer(query: str, docs: List[Any]) -> str:\n",
    "    \"\"\"LLM extracts directly from context\"\"\"\n",
    "    ctx = \"\\n\\n\".join(f\"[{i+1}] {d.page_content}\" for i, d in enumerate(docs[:6]))\n",
    "    prompt = f\"\"\"\n",
    "Answer the question below using only the provided CONTEXT.\n",
    "Each sentence should end with [1], [2], etc. referencing the numbered context.\n",
    "If context insufficient, write NOINFO.\n",
    "\n",
    "Question: {query}\n",
    "CONTEXT:\n",
    "{ctx}\n",
    "\"\"\"\n",
    "    ans = gemini.invoke(prompt).content.strip()\n",
    "    if ans.upper().startswith(\"NOINFO\") or len(ans) < 40:\n",
    "        return \"\"\n",
    "    return ans\n",
    "\n",
    "def scholarly_lookup(query: str, max_results=3):\n",
    "    \"\"\"Fetch scholarly refs (CrossRef â†’ Semantic Scholar fallback)\"\"\"\n",
    "    citations = []\n",
    "    try:\n",
    "        r = requests.get(f\"https://api.crossref.org/works?rows={max_results}&query={quote(query)}\", timeout=8).json()\n",
    "        for item in r.get(\"message\", {}).get(\"items\", []):\n",
    "            title = item.get(\"title\", [\"Untitled\"])[0]\n",
    "            authors = item.get(\"author\", [])\n",
    "            author_str = \", \".join(a.get(\"family\", \"\") for a in authors[:2]) or \"Unknown\"\n",
    "            if len(authors) > 2:\n",
    "                author_str += \" et al.\"\n",
    "            year = item.get(\"issued\", {}).get(\"date-parts\", [[None]])[0][0]\n",
    "            doi = item.get(\"DOI\", \"\")\n",
    "            link = f\"https://doi.org/{doi}\" if doi else item.get(\"URL\", \"\")\n",
    "            citations.append(f\"{author_str} ({year}). *{title}*. {link}\")\n",
    "        if citations:\n",
    "            return citations\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        s2 = requests.get(\n",
    "            f\"https://api.semanticscholar.org/graph/v1/paper/search?query={quote(query)}&limit={max_results}&fields=title,authors,year,url\",\n",
    "            timeout=8).json()\n",
    "        for item in s2.get(\"data\", []):\n",
    "            title = item.get(\"title\", \"Untitled\")\n",
    "            authors = item.get(\"authors\", [])\n",
    "            author_str = \", \".join(a.get(\"name\", \"\") for a in authors[:2]) or \"Unknown\"\n",
    "            if len(authors) > 2:\n",
    "                author_str += \" et al.\"\n",
    "            year = item.get(\"year\", \"n.d.\")\n",
    "            url = item.get(\"url\", \"\")\n",
    "            citations.append(f\"{author_str} ({year}). *{title}*. {url}\")\n",
    "    except:\n",
    "        pass\n",
    "    return citations or [\"(No scholarly reference found)\"]\n",
    "\n",
    "# ðŸ–‡ï¸ Make citations clickable\n",
    "def format_clickable_citations(citations: List[str]) -> str:\n",
    "    \"\"\"Converts citations to clickable markdown links\"\"\"\n",
    "    formatted = []\n",
    "    for i, c in enumerate(citations, start=1):\n",
    "        m = re.search(r'(https?://[^\\s]+|doi\\.org/[^\\s)]+)', c)\n",
    "        if m:\n",
    "            link = m.group(1).rstrip('.,)')\n",
    "            title_match = re.search(r\"\\*([^*]+)\\*\", c)\n",
    "            title = title_match.group(1) if title_match else f\"Source {i}\"\n",
    "            formatted.append(f\"[{i}] [{title}]({link})\")\n",
    "        else:\n",
    "            google_link = f\"https://www.google.com/search?q={quote(c)}\"\n",
    "            formatted.append(f\"[{i}] [Search on Google]({google_link})\")\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ“š Graph State\n",
    "# -----------------------------\n",
    "class GraphState(TypedDict):\n",
    "    query: str\n",
    "    answer: str\n",
    "    context: str\n",
    "    citations: List[str]\n",
    "    chat_history: List[Dict[str, str]]\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ§± Nodes\n",
    "# -----------------------------\n",
    "def db1_node(state: GraphState):\n",
    "    print(\"ðŸ”Ž DB1...\")\n",
    "    q = clean_query(state[\"query\"])\n",
    "    try:\n",
    "        docs = retriever1.get_relevant_documents(q)\n",
    "    except:\n",
    "        docs = []\n",
    "    if not docs:\n",
    "        return {**state, \"context\": \"no_db1\"}\n",
    "    ans = extractive_answer(q, docs)\n",
    "    if not ans:\n",
    "        return {**state, \"context\": \"no_db1\"}\n",
    "    link = f\"[Search on Google](https://www.google.com/search?q={quote(q)})\"\n",
    "    ans += f\"\\n\\nðŸ“š Citations:\\n{link}\"\n",
    "    return {**state, \"answer\": ans, \"context\": \"db1\", \"citations\": [link]}\n",
    "\n",
    "def db2_node(state: GraphState):\n",
    "    print(\"ðŸ”Ž DB2 (research)...\")\n",
    "    q = clean_query(state[\"query\"])\n",
    "    try:\n",
    "        docs = retriever2.get_relevant_documents(q)\n",
    "    except:\n",
    "        docs = []\n",
    "    if not docs:\n",
    "        return {**state, \"context\": \"no_db2\"}\n",
    "    ans = extractive_answer(q, docs)\n",
    "    if not ans:\n",
    "        return {**state, \"context\": \"no_db2\"}\n",
    "    refs = scholarly_lookup(q)\n",
    "    clickable_refs = format_clickable_citations(refs[:3])\n",
    "    ans += f\"\\n\\nðŸ“š Citations:\\n{clickable_refs}\"\n",
    "    return {**state, \"answer\": ans, \"context\": \"db2\", \"citations\": refs}\n",
    "\n",
    "def google_node(state: GraphState):\n",
    "    print(\"ðŸŒ Google...\")\n",
    "    q = clean_query(state[\"query\"])\n",
    "    raw = google_tool.run(q)\n",
    "    if not raw:\n",
    "        return {**state, \"context\": \"no_google\"}\n",
    "    link = f\"[Search on Google](https://www.google.com/search?q={quote(q)})\"\n",
    "    ans = gemini.invoke(f\"Answer this based on Google snippets:\\n{raw}\").content.strip()\n",
    "    ans += f\"\\n\\nðŸ“š Citations:\\n{link}\"\n",
    "    return {**state, \"answer\": ans, \"context\": \"google\", \"citations\": [link]}\n",
    "\n",
    "def wiki_node(state: GraphState):\n",
    "    print(\"ðŸ“– Wikipedia...\")\n",
    "    q = clean_query(state[\"query\"])\n",
    "    blob = wiki_tool.run(q)\n",
    "    if not blob:\n",
    "        return {**state, \"context\": \"no_wiki\"}\n",
    "    link = f\"[Wikipedia Search](https://en.wikipedia.org/wiki/Special:Search?search={quote(q)})\"\n",
    "    ans = gemini.invoke(f\"Answer using Wikipedia content:\\n{blob}\").content.strip()\n",
    "    ans += f\"\\n\\nðŸ“š Citations:\\n{link}\"\n",
    "    return {**state, \"answer\": ans, \"context\": \"wiki\", \"citations\": [link]}\n",
    "\n",
    "def gbif_node(state: GraphState):\n",
    "    print(\"ðŸŒ GBIF...\")\n",
    "    q = clean_query(state[\"query\"])\n",
    "    url = f\"https://api.gbif.org/v1/species/search?q={quote(q)}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=8).json()\n",
    "        results = r.get(\"results\", [])\n",
    "        if not results:\n",
    "            raise ValueError\n",
    "        lines = [f\"{it.get('scientificName','Unknown')} â€“ https://www.gbif.org/species/{it.get('key','')}\" for it in results[:5]]\n",
    "        link = f\"[GBIF Search](https://www.gbif.org/species/search?q={quote(q)})\"\n",
    "        ans = \"\\n\".join(lines) + f\"\\n\\nðŸ“š Citations:\\n{link}\"\n",
    "        return {**state, \"answer\": ans, \"context\": \"gbif\", \"citations\": [link]}\n",
    "    except:\n",
    "        return {**state, \"context\": \"no_gbif\"}\n",
    "\n",
    "def inat_node(state: GraphState):\n",
    "    print(\"ðŸ iNaturalist...\")\n",
    "    q = clean_query(state[\"query\"])\n",
    "    url = f\"https://api.inaturalist.org/v1/taxa/autocomplete?q={quote(q)}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=8).json()\n",
    "        results = r.get(\"results\", [])\n",
    "        if not results:\n",
    "            raise ValueError\n",
    "        lines = [f\"{it.get('name')} â€“ https://www.inaturalist.org/taxa/{it.get('id')}\" for it in results[:5]]\n",
    "        link = f\"[iNaturalist Search](https://www.inaturalist.org/search?q={quote(q)})\"\n",
    "        ans = \"\\n\".join(lines) + f\"\\n\\nðŸ“š Citations:\\n{link}\"\n",
    "        return {**state, \"answer\": ans, \"context\": \"inat\", \"citations\": [link]}\n",
    "    except:\n",
    "        return {**state, \"context\": \"no_inat\"}\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ§  Final Summarization\n",
    "# -----------------------------\n",
    "def final_node(state: GraphState):\n",
    "    print(\"ðŸ§  Summarizing...\")\n",
    "    q = clean_query(state[\"query\"])\n",
    "    base_answer = state[\"answer\"].strip()\n",
    "    citations = state.get(\"citations\", [])\n",
    "    summary_prompt = f\"\"\"\n",
    "Summarize the following into a concise, well-structured, factual answer.\n",
    "Preserve key technical details and remain accurate.\n",
    "\n",
    "Question: {q}\n",
    "\n",
    "Answer:\n",
    "{base_answer}\n",
    "\"\"\"\n",
    "    summary = gemini.invoke(summary_prompt).content.strip()\n",
    "    if citations:\n",
    "        formatted_cits = format_clickable_citations(citations)\n",
    "        summary += f\"\\n\\nðŸ“š Citations:\\n{formatted_cits}\"\n",
    "    return {**state, \"answer\": summary, \"context\": state[\"context\"]}\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ”€ Graph Construction\n",
    "# -----------------------------\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"db1\", db1_node)\n",
    "workflow.add_node(\"db2\", db2_node)\n",
    "workflow.add_node(\"google\", google_node)\n",
    "workflow.add_node(\"wiki\", wiki_node)\n",
    "workflow.add_node(\"gbif\", gbif_node)\n",
    "workflow.add_node(\"inat\", inat_node)\n",
    "workflow.add_node(\"final\", final_node)\n",
    "\n",
    "workflow.add_edge(START, \"db1\")\n",
    "workflow.add_conditional_edges(\"db1\", lambda s: s[\"context\"], {\"db1\": \"final\", \"no_db1\": \"db2\"})\n",
    "workflow.add_conditional_edges(\"db2\", lambda s: s[\"context\"], {\"db2\": \"final\", \"no_db2\": \"google\"})\n",
    "workflow.add_conditional_edges(\"google\", lambda s: s[\"context\"], {\"google\": \"final\", \"no_google\": \"wiki\"})\n",
    "workflow.add_conditional_edges(\"wiki\", lambda s: s[\"context\"], {\"wiki\": \"final\", \"no_wiki\": \"gbif\"})\n",
    "workflow.add_conditional_edges(\"gbif\", lambda s: s[\"context\"], {\"gbif\": \"final\", \"no_gbif\": \"inat\"})\n",
    "workflow.add_edge(\"inat\", \"final\")\n",
    "workflow.add_edge(\"final\", END)\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"âœ… Pipeline ready: DB1 â†’ DB2 â†’ Google â†’ Wiki â†’ GBIF â†’ iNat â†’ Summarize\")\n",
    "\n",
    "def resolve_context_pronouns(query: str, memory: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"Expands pronouns like 'it', 'they', etc. based on recent conversation memory.\"\"\"\n",
    "    if not memory:\n",
    "        return query\n",
    "\n",
    "    # Find most recent meaningful topic\n",
    "    recent_answers = [m.get(\"answer\", \"\") for m in memory[-3:] if m.get(\"answer\")]\n",
    "    if not recent_answers:\n",
    "        return query\n",
    "\n",
    "    context_text = \" \".join(recent_answers[-3:])\n",
    "    context_prompt = f\"\"\"\n",
    "You are a contextual assistant. Replace vague pronouns (like it, they, them, he, she, etc.)\n",
    "in the user's question with the specific subject from the recent conversation.\n",
    "\n",
    "Example:\n",
    "- Context: \"BeeMachine is a platform that identifies bees.\"\n",
    "- Query: \"Who developed it?\"\n",
    "- Output: \"Who developed BeeMachine?\"\n",
    "\n",
    "Now do this for:\n",
    "Context: {context_text}\n",
    "Query: {query}\n",
    "\n",
    "Output only the rewritten question:\n",
    "\"\"\"\n",
    "    rewritten = gemini.invoke(context_prompt).content.strip()\n",
    "    if len(rewritten) < 5 or rewritten.lower() == query.lower():\n",
    "        return query\n",
    "    return rewritten\n",
    "\n",
    "# -----------------------------\n",
    "def ask(question: str):\n",
    "    mem = load_memory()\n",
    "\n",
    "    # ðŸ” Step 1: Contextual rewrite\n",
    "    resolved_query = resolve_context_pronouns(question, mem)\n",
    "    if resolved_query != question:\n",
    "        print(f\"ðŸ’¡ Interpreted query as: â€œ{resolved_query}â€\")\n",
    "\n",
    "    # ðŸ”„ Step 2: Run pipeline\n",
    "    result = graph.invoke({\n",
    "        \"query\": resolved_query,\n",
    "        \"answer\": \"\",\n",
    "        \"context\": \"\",\n",
    "        \"citations\": [],\n",
    "        \"chat_history\": mem\n",
    "    })\n",
    "\n",
    "    # ðŸ’¬ Step 3: Output\n",
    "    print(\"\\nChatbot:\\n\")\n",
    "    print(result[\"answer\"])\n",
    "    print(f\"\\nðŸ§­ Pipeline completed at source: {result['context']}\")\n",
    "\n",
    "    # ðŸ§  Step 4: Update memory\n",
    "    mem.append({\"query\": question, \"resolved_query\": resolved_query, \"answer\": result[\"answer\"]})\n",
    "    save_memory(mem)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
